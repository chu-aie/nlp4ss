{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Climate Risk Analysis of Sierra Club Press Releases\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This project aims to analyze Sierra Club press releases to identify and quantify mentions of climate risks, focusing on transition risks and physical risks. We'll use both traditional (TF-IDF) and modern (BERT) NLP techniques to process and analyze the text data.\n",
    "\n",
    "## Installation\n",
    "\n",
    "Before we begin, let's install the necessary packages for this lab. Run the following cell to install the required libraries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J5WPTRBFW4YN46S1MNHJ1JTE",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install nlp4ss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Data Loading\n",
    "\n",
    "- We import necessary libraries and initialize the project environment using HyFI.\n",
    "- NLTK data is downloaded for text processing tasks.\n",
    "- The Sierra Club press release data is loaded from a JSONL file into a pandas DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J5WQ6QMDM4GJTR1KBQTSFGCF",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyfi import HyFI\n",
    "\n",
    "if HyFI.is_colab():\n",
    "    HyFI.mount_google_drive()\n",
    "    project_root = \"/content/drive/MyDrive/nlp4ss\"\n",
    "else:\n",
    "    project_root = \"$HOME/workspace/courses/nlp4ss\"\n",
    "\n",
    "h = HyFI.initialize(\n",
    "    project_name=\"nlp4ss\",\n",
    "    project_root=project_root,\n",
    "    logging_level=\"INFO\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"Project directory:\", h.project.root_dir)\n",
    "print(\"Project workspace directory:\", h.project.workspace_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J5WQ7T7EZ5CHV1NM6C9KPC7Q",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import gensim.downloader as api\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"punkt_tab\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J5YK28NGGTRJ6YC547Y6ZBFP",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "raw_data_file = h.project.workspace_dir / \"data/raw/articles.jsonl\"\n",
    "rdata = h.load_dataset(\"json\", data_files=raw_data_file.as_posix())\n",
    "df = rdata[\"train\"].to_pandas()\n",
    "\n",
    "print(df.info())\n",
    "print(\"\\nSample of the data:\")\n",
    "print(df.head())\n",
    "\n",
    "# Sample data\n",
    "df = df.sample(500, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Initial Climate Risk Keywords\n",
    "\n",
    "- We start with two lists of initial keywords: one for transition risks and another for physical risks.\n",
    "- These keywords are based on common terms associated with each type of climate risk.\n",
    "\n",
    "> Bua, G., Kapp, D., Ramella, F., & Rognone, L. (2024). Transition versus physical climate risk pricing in European financial markets: A text-based approach. The European Journal of Finance, 1-35.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J5YK28NGXPXHXHRPHPK2GWSX",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial keyword lists\n",
    "initial_transition_risk_keywords = [\n",
    "    \"EJ/YR\",\n",
    "    \"Radiative Forcing\",\n",
    "    \"HCFC\",\n",
    "    \"Ozone\",\n",
    "    \"Bioenergy\",\n",
    "    \"Technical Potential\",\n",
    "    \"GHG Emissions\",\n",
    "    \"Refrigerant\",\n",
    "    \"IPCC\",\n",
    "    \"GHG\",\n",
    "    \"Ozone Layer\",\n",
    "    \"Geothermal\",\n",
    "    \"Pathways\",\n",
    "    \"Exajoules\",\n",
    "    \"Biomass\",\n",
    "    \"Hydropower\",\n",
    "    \"GigaJoules\",\n",
    "    \"Photovoltaics\",\n",
    "    \"Chlorofluorocarbon\",\n",
    "    \"Heat Pumps\",\n",
    "    \"Ocean Energies\",\n",
    "    \"Carbon Dioxide Capture and Storage\",\n",
    "    \"Mitigation Scenarios\",\n",
    "    \"Lifecycle\",\n",
    "    \"USD/kWh\",\n",
    "    \"Fluid\",\n",
    "    \"Equivalent CO2\",\n",
    "    \"Methane\",\n",
    "    \"Halon\",\n",
    "    \"Blowing Agent\",\n",
    "    \"Aerosols\",\n",
    "    \"Leakage\",\n",
    "    \"Sustainable Development\",\n",
    "    \"UNEP\",\n",
    "    \"Montreal Protocol\",\n",
    "    \"Anthropogenic\",\n",
    "    \"Radiative\",\n",
    "    \"Wind Energy\",\n",
    "    \"Solar energy\",\n",
    "    \"Hydrogen\",\n",
    "    \"UNFCCC\",\n",
    "    \"Product carbon footprints\",\n",
    "    \"report safeguarding\",\n",
    "    \"geological storage\",\n",
    "    \"direct solar\",\n",
    "    \"Reservoir\",\n",
    "    \"IEA\",\n",
    "    \"anthropogenic\",\n",
    "    \"adaptation options\",\n",
    "    \"ecosystems\",\n",
    "    \"global warming potential\",\n",
    "    \"ozone-depleting substances\",\n",
    "    \"GTCO2\",\n",
    "    \"global warming\",\n",
    "    \"primary energies\",\n",
    "    \"ocean\",\n",
    "    \"atmosphere\",\n",
    "    \"EQ/YR\",\n",
    "    \"dioxide capture and storage\",\n",
    "    \"methane\",\n",
    "    \"ocean storage\",\n",
    "    \"equivalent\",\n",
    "    \"dioxide capture\",\n",
    "    \"change mitigation\",\n",
    "    \"teap\",\n",
    "    \"levels cost\",\n",
    "    \"energies systems\",\n",
    "    \"life cycle climate performance\",\n",
    "    \"mitigation options\",\n",
    "    \"capacity factors\",\n",
    "    \"TWH/YR\",\n",
    "    \"feedstock\",\n",
    "    \"foam\",\n",
    "    \"solvent\",\n",
    "    \"biofuels\",\n",
    "    \"ozone depletion\",\n",
    "    \"sustainable development\",\n",
    "    \"Tco2\",\n",
    "    \"MTCO2\",\n",
    "    \"MTCO2 EQ\",\n",
    "    \"stratospheric\",\n",
    "    \"climate systems\",\n",
    "    \"troposphere\",\n",
    "    \"investment cost\",\n",
    "    \"human system\",\n",
    "]\n",
    "\n",
    "initial_physical_risk_keywords = [\n",
    "    \"coastal\",\n",
    "    \"ecosystem services\",\n",
    "    \"climate models\",\n",
    "    \"wetlands\",\n",
    "    \"ipcc\",\n",
    "    \"adaptation\",\n",
    "    \"ryosphere\",\n",
    "    \"ice sheet\",\n",
    "    \"biodiversity\",\n",
    "    \"species\",\n",
    "    \"phytoplankton\",\n",
    "    \"antarctic\",\n",
    "    \"climate variables\",\n",
    "    \"biophysical\",\n",
    "    \"ghg\",\n",
    "    \"pathways\",\n",
    "    \"climate change\",\n",
    "    \"precipitation\",\n",
    "    \"anthropogenic\",\n",
    "    \"coupled model\",\n",
    "    \"intercomparison projects\",\n",
    "    \"cyclones\",\n",
    "    \"climate related\",\n",
    "    \"ocean\",\n",
    "    \"streamflow\",\n",
    "    \"adaptation response\",\n",
    "    \"change impacts\",\n",
    "    \"observed change\",\n",
    "    \"socioeconomic\",\n",
    "    \"freshwater\",\n",
    "    \"temperature increase\",\n",
    "    \"coastal zones\",\n",
    "    \"sea level\",\n",
    "    \"phenology\",\n",
    "    \"future climate\",\n",
    "    \"upwelling\",\n",
    "    \"fisheries\",\n",
    "    \"hazards\",\n",
    "    \"general circulation models\",\n",
    "    \"nutrient\",\n",
    "    \"adaptation\",\n",
    "    \"permafrost\",\n",
    "    \"arid\",\n",
    "    \"reefs\",\n",
    "    \"water resources\",\n",
    "    \"terrestrial\",\n",
    "    \"spatial\",\n",
    "    \"coral\",\n",
    "    \"land degradation\",\n",
    "    \"RCP\",\n",
    "    \"adaptation planning\",\n",
    "    \"change climate\",\n",
    "    \"glaciers\",\n",
    "    \"salinity\",\n",
    "    \"hydrological variables\",\n",
    "    \"sediment\",\n",
    "    \"tropical cyclones\",\n",
    "    \"latitudes\",\n",
    "    \"projected change\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J5YK4CJBC1ZE3YN5W98VWZ98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Convert to lowercase and remove special characters\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text.lower())\n",
    "\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords and short words\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    tokens = [t for t in tokens if t not in stop_words and len(t) > 3]\n",
    "\n",
    "    # Lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "\n",
    "# Preprocess keywords\n",
    "initial_transition_risk_keywords = [\n",
    "    preprocess_text(keyword) for keyword in initial_transition_risk_keywords\n",
    "]\n",
    "initial_physical_risk_keywords = [\n",
    "    preprocess_text(keyword) for keyword in initial_physical_risk_keywords\n",
    "]\n",
    "\n",
    "# Remove duplicates\n",
    "initial_transition_risk_keywords = list(set(initial_transition_risk_keywords))\n",
    "physicalinitial_physical_risk_keywords_risk_keywords = list(\n",
    "    set(initial_physical_risk_keywords)\n",
    ")\n",
    "\n",
    "# Replace space with underscore\n",
    "initial_transition_risk_keywords = [\n",
    "    keyword.replace(\" \", \"_\")\n",
    "    for keyword in initial_transition_risk_keywords\n",
    "    if len(keyword) > 0\n",
    "]\n",
    "initial_physical_risk_keywords = [\n",
    "    keyword.replace(\" \", \"_\")\n",
    "    for keyword in initial_physical_risk_keywords\n",
    "    if len(keyword) > 0\n",
    "]\n",
    "\n",
    "print(\"Number of transition risk keywords:\", len(initial_transition_risk_keywords))\n",
    "print(\"Transition risk keywords:\", initial_transition_risk_keywords)\n",
    "\n",
    "print(\"Number of physical risk keywords:\", len(initial_physical_risk_keywords))\n",
    "print(\"Physical risk keywords:\", initial_physical_risk_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expand Keywords Using Word Embeddings\n",
    "\n",
    "- We use pre-trained Word2Vec embeddings to find semantically similar words to our initial keywords.\n",
    "- The `expand_keywords` function takes a list of keywords and returns an expanded list of related terms.\n",
    "- We combine the original keywords with the expanded ones to create our final keyword lists.\n",
    "- This expansion helps capture a broader range of terms related to climate risks, potentially improving our analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J5YK28NGCCGSH9GMY7VPC0E5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Load pre-trained word embeddings\n",
    "word2vec_model = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "\n",
    "def expand_keywords(keywords, model, topn=5):\n",
    "    expanded_keywords = set()\n",
    "    for keyword in keywords:\n",
    "        try:\n",
    "            similar_words = model.most_similar(keyword, topn=topn)\n",
    "            expanded_keywords.update([word.lower() for word, _ in similar_words])\n",
    "        except KeyError:\n",
    "            continue  # Skip words not in the vocabulary\n",
    "    return list(expanded_keywords)\n",
    "\n",
    "\n",
    "# Expand keyword lists\n",
    "expanded_transition_keywords = expand_keywords(\n",
    "    initial_transition_risk_keywords, word2vec_model\n",
    ")\n",
    "expanded_physical_keywords = expand_keywords(\n",
    "    initial_physical_risk_keywords, word2vec_model\n",
    ")\n",
    "\n",
    "# Combine original and expanded keywords\n",
    "transition_risk_keywords = (\n",
    "    initial_transition_risk_keywords + expanded_transition_keywords\n",
    ")\n",
    "physical_risk_keywords = initial_physical_risk_keywords + expanded_physical_keywords\n",
    "\n",
    "# Remove duplicates\n",
    "transition_risk_keywords = list(set(transition_risk_keywords))\n",
    "physical_risk_keywords = list(set(physical_risk_keywords))\n",
    "\n",
    "print(\"Number of expanded transition risk keywords:\", len(transition_risk_keywords))\n",
    "print(\"Number of expanded physical risk keywords:\", len(physical_risk_keywords))\n",
    "\n",
    "print(\"Expanded transition risk keywords:\", transition_risk_keywords)\n",
    "print(\"Expanded physical risk keywords:\", physical_risk_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing\n",
    "\n",
    "- We define a function to preprocess the text, which includes:\n",
    "  - Converting to lowercase\n",
    "  - Tokenizing the text\n",
    "  - Creating both unigrams and bigrams\n",
    "- This preprocessing step is crucial for capturing both single words and two-word phrases in our analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J5YK28NG9X9P9ZYQYTTAAKHP",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text to include bigrams\n",
    "def preprocess_text_with_bigrams(text):\n",
    "    # Convert to lowercase and tokenize\n",
    "    tokens = preprocess_text(text).split()\n",
    "    # Create unigrams and bigrams\n",
    "    unigrams = tokens\n",
    "    bigrams = [f\"{tokens[i]}_{tokens[i+1]}\" for i in range(len(tokens) - 1)]\n",
    "    return unigrams + bigrams\n",
    "\n",
    "\n",
    "# Update the dataframe with preprocessed text including bigrams\n",
    "df[\"processed_content_bigrams\"] = (\n",
    "    df[\"content\"].apply(preprocess_text_with_bigrams).apply(\" \".join)\n",
    ")\n",
    "\n",
    "# Print the updated dataframe\n",
    "df[[\"processed_content_bigrams\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Analysis\n",
    "\n",
    "- We use TF-IDF (Term Frequency-Inverse Document Frequency) to analyze the importance of climate risk keywords in each document.\n",
    "- The TF-IDF vectorizer is configured to use our specific climate risk vocabulary.\n",
    "- We calculate separate scores for transition risks and physical risks based on the TF-IDF matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J5YK28NG88DNQ8AKG3BVDHH7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# TF-IDF Analysis with bigrams\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    vocabulary=set(transition_risk_keywords + physical_risk_keywords)\n",
    ")\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df[\"processed_content_bigrams\"])\n",
    "\n",
    "# Calculate risk scores using sum method\n",
    "df[\"tfidf_transition_score_sum\"] = tfidf_matrix[\n",
    "    :,\n",
    "    [\n",
    "        tfidf_vectorizer.vocabulary_.get(word)\n",
    "        for word in transition_risk_keywords\n",
    "        if word in tfidf_vectorizer.vocabulary_\n",
    "    ],\n",
    "].sum(axis=1)\n",
    "df[\"tfidf_physical_score_sum\"] = tfidf_matrix[\n",
    "    :,\n",
    "    [\n",
    "        tfidf_vectorizer.vocabulary_.get(word)\n",
    "        for word in physical_risk_keywords\n",
    "        if word in tfidf_vectorizer.vocabulary_\n",
    "    ],\n",
    "].sum(axis=1)\n",
    "\n",
    "# Calculate risk scores using cosine similarity\n",
    "transition_risk_keywords_vector = tfidf_vectorizer.transform(transition_risk_keywords)\n",
    "physical_risk_keywords_vector = tfidf_vectorizer.transform(physical_risk_keywords)\n",
    "df[\"tfidf_transition_score_sim\"] = df[\"processed_content_bigrams\"].apply(\n",
    "    lambda x: cosine_similarity(\n",
    "        tfidf_vectorizer.transform([x]), transition_risk_keywords_vector\n",
    "    ).mean()\n",
    ")\n",
    "df[\"tfidf_physical_score_sim\"] = df[\"processed_content_bigrams\"].apply(\n",
    "    lambda x: cosine_similarity(\n",
    "        tfidf_vectorizer.transform([x]), physical_risk_keywords_vector\n",
    "    ).mean()\n",
    ")\n",
    "\n",
    "# Normalize scores\n",
    "for col in [\n",
    "    \"tfidf_transition_score_sum\",\n",
    "    \"tfidf_physical_score_sum\",\n",
    "    \"tfidf_transition_score_sim\",\n",
    "    \"tfidf_physical_score_sim\",\n",
    "]:\n",
    "    df[col] = (df[col] - df[col].min()) / (df[col].max() - df[col].min())\n",
    "\n",
    "# Combine scores\n",
    "df[\"tfidf_transition_score\"] = (\n",
    "    df[\"tfidf_transition_score_sum\"] + df[\"tfidf_transition_score_sim\"]\n",
    ") / 2\n",
    "df[\"tfidf_physical_score\"] = (\n",
    "    df[\"tfidf_physical_score_sum\"] + df[\"tfidf_physical_score_sim\"]\n",
    ") / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J5YK28NG92MNJJJ3NQ8Z4P7H",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "print(\"Top 10 articles by TF-IDF physical risk score (combined):\")\n",
    "print(\n",
    "    df[[\"processed_content_bigrams\", \"tfidf_physical_score\"]]\n",
    "    .sort_values(\"tfidf_physical_score\", ascending=False)\n",
    "    .head(10)\n",
    ")\n",
    "\n",
    "print(\"\\nTop 10 articles by TF-IDF transition risk score (combined):\")\n",
    "print(\n",
    "    df[[\"processed_content_bigrams\", \"tfidf_transition_score\"]]\n",
    "    .sort_values(\"tfidf_transition_score\", ascending=False)\n",
    "    .head(10)\n",
    ")\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(df[\"tfidf_transition_score\"], df[\"tfidf_physical_score\"], alpha=0.5)\n",
    "plt.xlabel(\"TF-IDF Transition Risk Score (Combined)\")\n",
    "plt.ylabel(\"TF-IDF Physical Risk Score (Combined)\")\n",
    "plt.title(\"TF-IDF: Transition vs Physical Risk in Sierra Club Press Releases\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT-based Analysis\n",
    "\n",
    "- We use BERT (Bidirectional Encoder Representations from Transformers) for a more context-aware analysis of climate risk mentions.\n",
    "- The `get_bert_embedding` function generates embeddings for text using BERT.\n",
    "- The `contextual_keyword_importance` function calculates the importance of keywords in the context of each document, considering both semantic similarity (via BERT embeddings) and keyword frequency.\n",
    "- We calculate BERT-based scores for both transition and physical risks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J5YK28NGMBMYG3PSG8JE38HJ",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J5YK28NG57ZBZGD6734R6EY6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def get_bert_embedding(text):\n",
    "    inputs = tokenizer(\n",
    "        text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512\n",
    "    )\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).cpu().numpy().flatten()\n",
    "\n",
    "\n",
    "def contextual_keyword_importance(text, keywords):\n",
    "    # Get BERT embeddings for the full text and keywords\n",
    "    text_embedding = get_bert_embedding(text)\n",
    "    keyword_embeddings = np.array(\n",
    "        [get_bert_embedding(keyword.replace(\"_\", \" \")) for keyword in keywords]\n",
    "    )\n",
    "\n",
    "    # Calculate attention scores\n",
    "    attention_scores = cosine_similarity(\n",
    "        text_embedding.reshape(1, -1), keyword_embeddings\n",
    "    ).flatten()\n",
    "\n",
    "    # Count keyword occurrences (considering bigrams)\n",
    "    keyword_counts = np.array(\n",
    "        [text.lower().count(keyword.replace(\"_\", \" \")) for keyword in keywords]\n",
    "    )\n",
    "\n",
    "    # Combine attention scores and counts\n",
    "    importance_scores = attention_scores * keyword_counts\n",
    "\n",
    "    return importance_scores.sum()\n",
    "\n",
    "\n",
    "# Calculate BERT-based scores\n",
    "df[\"bert_transition_score\"] = df[\"content\"].apply(\n",
    "    lambda x: contextual_keyword_importance(x, transition_risk_keywords)\n",
    ")\n",
    "df[\"bert_physical_score\"] = df[\"content\"].apply(\n",
    "    lambda x: contextual_keyword_importance(x, physical_risk_keywords)\n",
    ")\n",
    "\n",
    "# Normalize scores\n",
    "for col in [\"bert_transition_score\", \"bert_physical_score\"]:\n",
    "    df[col] = (df[col] - df[col].min()) / (df[col].max() - df[col].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Analysis and Visualization\n",
    "\n",
    "- We display the top 10 articles for each risk type and analysis method.\n",
    "- Scatter plots are created to visualize the relationship between transition and physical risk scores for both TF-IDF and BERT methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J5YK28NHJ6EKDDH3H89YTEBW",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "print(\"Top 10 articles by TF-IDF transition risk score:\")\n",
    "print(\n",
    "    df[[\"content\", \"tfidf_transition_score\"]]\n",
    "    .sort_values(\"tfidf_transition_score\", ascending=False)\n",
    "    .head(10)\n",
    ")\n",
    "\n",
    "print(\"\\nTop 10 articles by TF-IDF physical risk score:\")\n",
    "print(\n",
    "    df[[\"content\", \"tfidf_physical_score\"]]\n",
    "    .sort_values(\"tfidf_physical_score\", ascending=False)\n",
    "    .head(10)\n",
    ")\n",
    "\n",
    "print(\"\\nTop 10 articles by BERT transition risk score:\")\n",
    "print(\n",
    "    df[[\"content\", \"bert_transition_score\"]]\n",
    "    .sort_values(\"bert_transition_score\", ascending=False)\n",
    "    .head(10)\n",
    ")\n",
    "\n",
    "print(\"\\nTop 10 articles by BERT physical risk score:\")\n",
    "print(\n",
    "    df[[\"content\", \"bert_physical_score\"]]\n",
    "    .sort_values(\"bert_physical_score\", ascending=False)\n",
    "    .head(10)\n",
    ")\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(df[\"tfidf_transition_score\"], df[\"tfidf_physical_score\"], alpha=0.5)\n",
    "plt.xlabel(\"TF-IDF Transition Risk Score\")\n",
    "plt.ylabel(\"TF-IDF Physical Risk Score\")\n",
    "plt.title(\"TF-IDF: Transition vs Physical Risk in Sierra Club Press Releases\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(df[\"bert_transition_score\"], df[\"bert_physical_score\"], alpha=0.5)\n",
    "plt.xlabel(\"BERT Transition Risk Score\")\n",
    "plt.ylabel(\"BERT Physical Risk Score\")\n",
    "plt.title(\"BERT: Transition vs Physical Risk in Sierra Club Press Releases\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Analysis\n",
    "\n",
    "- We convert the timestamp to a datetime index and resample the data to monthly averages.\n",
    "- A time series plot is created to show how different risk scores change over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J5YK28NHX18TH78TN2X4D6E4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series analysis\n",
    "df[\"date\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"date\"])\n",
    "df.set_index(\"date\", inplace=True)\n",
    "\n",
    "# Monthly average risk scores\n",
    "monthly_risks = df.resample(\"M\")[\n",
    "    [\n",
    "        \"tfidf_physical_score\",\n",
    "        \"tfidf_transition_score\",\n",
    "        \"bert_physical_score\",\n",
    "        \"bert_transition_score\",\n",
    "    ]\n",
    "].mean()\n",
    "\n",
    "# Plot time series\n",
    "plt.figure(figsize=(14, 7))\n",
    "monthly_risks.plot()\n",
    "plt.title(\"Monthly Average Risk Scores Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Risk Score\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword Frequency Analysis\n",
    "\n",
    "- We analyze the frequency of each keyword in the entire corpus.\n",
    "- The results are displayed for the top 20 most frequent keywords in each category.\n",
    "- Bar plots are created to visualize the top 10 keywords for each risk type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J5YK28NHPPXV51QXW31K14KS",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_keyword_frequency(keywords, df_column):\n",
    "    keyword_freq = {\n",
    "        keyword: df_column.apply(lambda x: x.count(keyword.replace(\"_\", \" \"))).sum()\n",
    "        for keyword in keywords\n",
    "    }\n",
    "    return pd.Series(keyword_freq).sort_values(ascending=False)\n",
    "\n",
    "\n",
    "transition_freq = analyze_keyword_frequency(\n",
    "    transition_risk_keywords, df[\"processed_content_bigrams\"]\n",
    ")\n",
    "physical_freq = analyze_keyword_frequency(\n",
    "    physical_risk_keywords, df[\"processed_content_bigrams\"]\n",
    ")\n",
    "\n",
    "print(\"Top 20 most frequent transition risk keywords:\")\n",
    "print(transition_freq.head(20))\n",
    "\n",
    "print(\"\\nTop 20 most frequent physical risk keywords:\")\n",
    "print(physical_freq.head(20))\n",
    "\n",
    "# Visualize top keywords\n",
    "plt.figure(figsize=(12, 6))\n",
    "transition_freq.head(10).plot(kind=\"bar\")\n",
    "plt.title(\"Top 10 Transition Risk Keywords\")\n",
    "plt.xlabel(\"Keywords\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "physical_freq.head(10).plot(kind=\"bar\")\n",
    "plt.title(\"Top 10 Physical Risk Keywords\")\n",
    "plt.xlabel(\"Keywords\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This project presents a comprehensive analysis of climate risk discussions in Sierra Club press releases, utilizing both traditional (TF-IDF) and modern (BERT) NLP techniques. By examining transition and physical risks separately, we gain valuable insights into how different aspects of climate change are addressed in environmental communications.\n",
    "\n",
    "Key findings and implications:\n",
    "\n",
    "1. Temporal Trends: The time series analysis reveals evolving patterns in climate risk discourse, potentially reflecting changing priorities or external events influencing the Sierra Club's messaging.\n",
    "\n",
    "2. Risk Type Comparison: By quantifying the emphasis on transition versus physical risks, we can understand which aspects of climate change receive more attention in the organization's communications.\n",
    "\n",
    "3. Keyword Analysis: The frequency analysis of specific climate risk terms provides a granular view of the most prominent topics within each risk category, offering insights into the Sierra Club's focus areas.\n",
    "\n",
    "4. Methodological Comparison: The use of both TF-IDF and BERT-based approaches allows for a nuanced understanding of climate risk mentions, showcasing the strengths and potential complementarity of different NLP techniques.\n",
    "\n",
    "5. Keyword Expansion Impact: The incorporation of word embeddings to expand our initial keyword lists demonstrates how semantic relationships can enhance the detection of climate risk discussions, potentially capturing more nuanced or varied terminology.\n",
    "\n",
    "Limitations and Future Directions:\n",
    "\n",
    "- While keyword expansion increases coverage, it may introduce some noise. Future work could involve refining the expanded keyword list based on domain expertise.\n",
    "- The analysis could be extended to compare results using initial versus expanded keyword lists to quantify the impact of this approach.\n",
    "- Experimenting with different word embedding models or expansion techniques could further optimize the keyword selection process.\n",
    "- Comparative analysis with other environmental organizations' communications could provide broader context for the Sierra Club's approach to climate risk discussion.\n",
    "\n",
    "This project demonstrates the potential of combining traditional and modern NLP techniques to analyze complex environmental communications. By providing a data-driven approach to understanding climate risk discourse, this analysis can inform strategic communication decisions, policy discussions, and further research in environmental studies and climate change communication.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp4ss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
